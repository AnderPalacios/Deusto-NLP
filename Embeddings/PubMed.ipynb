{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59cb61dd",
   "metadata": {},
   "source": [
    "## **Making Embeddings for PubMed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "922581c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2b97270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = pd.read_csv(\"../PubMed_dataset.csv\")\n",
    "\n",
    "# Load pretrained Word2Vec model\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833c48c2",
   "metadata": {},
   "source": [
    "### **Word2Vec Embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12cd15a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PMID                                       Abstract_W2V\n",
      "0  12187484  [-0.03999741, 0.062728785, -0.002549661, 0.049...\n",
      "1   2344352  [0.014284923, 0.03845855, 0.020136734, 0.05924...\n",
      "2  14654069  [-0.020149924, 0.047227394, 0.012617389, 0.035...\n",
      "3  16443886  [-0.045007102, 0.025433676, -0.005037438, 0.06...\n",
      "4   2684155  [-0.028360292, 0.05821858, 0.015442131, 0.0421...\n"
     ]
    }
   ],
   "source": [
    "# Word2Vec embeddings\n",
    "\n",
    "# Get embedding for a single abstract\n",
    "def abstract_to_w2v(abstract, w2v_model, vector_size=300):\n",
    "    # Tokenize by simple whitespace and lowercase\n",
    "    tokens = abstract.lower().split()\n",
    "    # Filter tokens that exist in the Word2Vec vocabulary\n",
    "    valid_tokens = [t for t in tokens if t in w2v_model]\n",
    "    \n",
    "    if not valid_tokens:  # If no tokens are in the vocab, return 300D vector of zeros\n",
    "        return np.zeros(vector_size)\n",
    "    \n",
    "    # Average embeddings\n",
    "    embeddings = np.array([w2v_model[t] for t in valid_tokens])\n",
    "    return embeddings.mean(axis=0)\n",
    "\n",
    "vector_size = 300  \n",
    "dataset[\"Abstract_W2V\"] = dataset[\"Abstract\"].apply(lambda x: abstract_to_w2v(x, model, vector_size))\n",
    "\n",
    "# Check the result\n",
    "print(dataset[[\"PMID\", \"Abstract_W2V\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb55ef97",
   "metadata": {},
   "source": [
    "### **BERT Embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92625ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19716/19716 [8:14:00<00:00,  1.50s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (19716, 768)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pandas as pd\n",
    "\n",
    "MODEL_FOLDER = \"./daberta_finetune_head_PubMed\" \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_FOLDER)\n",
    "model = AutoModel.from_pretrained(MODEL_FOLDER)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()  \n",
    "\n",
    "# Function to get embeddings\n",
    "def get_bert_embedding(text, tokenizer, model, device, max_length=512):\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    input_ids = encoding[\"input_ids\"].to(device)\n",
    "    attention_mask = encoding[\"attention_mask\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        last_hidden_state = outputs.last_hidden_state  # shape: (1, seq_len, hidden_size)\n",
    "        cls_embedding = last_hidden_state[:, 0, :]      # CLS token embedding\n",
    "        return cls_embedding.squeeze().cpu().numpy()\n",
    "\n",
    "# Compute embeddings for all abstracts\n",
    "embeddings = []\n",
    "\n",
    "for abstract in tqdm(dataset['Abstract']):\n",
    "    emb = get_bert_embedding(abstract, tokenizer, model, device)\n",
    "    embeddings.append(emb)\n",
    "\n",
    "\n",
    "embeddings = np.array(embeddings)\n",
    "print(\"Embeddings shape:\", embeddings.shape)  # (num_abstracts, hidden_size)\n",
    "\n",
    "# Add embeddings to the DataFrame\n",
    "dataset['bert_embedding'] = list(embeddings)\n",
    "\n",
    "dataset.to_csv(\"PubMed_dataset_EMBS.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5820946c",
   "metadata": {},
   "source": [
    "### **Get all Embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8151bb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns of the dataset: Index(['PMID', 'Abstract_W2V', 'Title', 'Abstract', 'Key_words', 'Authors',\n",
      "       'label', 'TFIDF', 'summary_words', 'bert_embedding'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "BERT_embs = pd.read_csv(\"./PubMed_dataset_EMBS.csv\")\n",
    "df_with_EMBS = pd.merge(dataset[['PMID', 'Abstract_W2V']], BERT_embs, on='PMID')\n",
    "\n",
    "print(f\"Columns of the dataset: {df_with_EMBS.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d622ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>TFIDF</th>\n",
       "      <th>Abstract_W2V</th>\n",
       "      <th>bert_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12187484</td>\n",
       "      <td>PURPOSE: Dogs and rats are commonly used to ex...</td>\n",
       "      <td>{'rat': 0.09393489570187145, 'common': 0.02869...</td>\n",
       "      <td>[-0.03999741, 0.062728785, -0.002549661, 0.049...</td>\n",
       "      <td>[ 5.83067238e-02 -7.34468549e-03 -7.10018054e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2344352</td>\n",
       "      <td>Phase-modulated rotating-frame imaging (p.m.r....</td>\n",
       "      <td>{'rat': 0.023617916633613394, 'use': 0.0147841...</td>\n",
       "      <td>[0.014284923, 0.03845855, 0.020136734, 0.05924...</td>\n",
       "      <td>[ 8.21016803e-02 -9.57140699e-03 -8.19785297e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14654069</td>\n",
       "      <td>Cardiovascular complications are the primary c...</td>\n",
       "      <td>{'rat': 0.10226314418677966, 'use': 0.01066898...</td>\n",
       "      <td>[-0.020149924, 0.047227394, 0.012617389, 0.035...</td>\n",
       "      <td>[ 6.06562942e-02 -2.23077759e-02 -8.84668827e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16443886</td>\n",
       "      <td>OBJECTIVE: Mean blood glucose (MBG) over 2-3 m...</td>\n",
       "      <td>{'model': 0.038714646134547365, 'develop': 0.0...</td>\n",
       "      <td>[-0.045007102, 0.025433676, -0.005037438, 0.06...</td>\n",
       "      <td>[ 5.10609150e-02 -4.73604724e-03 -7.53103644e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2684155</td>\n",
       "      <td>Hepatocytes were derived from 2-3-day streptoz...</td>\n",
       "      <td>{'rat': 0.030615817858387732, 'anim': 0.080179...</td>\n",
       "      <td>[-0.028360292, 0.05821858, 0.015442131, 0.0421...</td>\n",
       "      <td>[ 6.99397400e-02 -1.28354207e-02 -8.73763263e-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PMID                                           Abstract  \\\n",
       "0  12187484  PURPOSE: Dogs and rats are commonly used to ex...   \n",
       "1   2344352  Phase-modulated rotating-frame imaging (p.m.r....   \n",
       "2  14654069  Cardiovascular complications are the primary c...   \n",
       "3  16443886  OBJECTIVE: Mean blood glucose (MBG) over 2-3 m...   \n",
       "4   2684155  Hepatocytes were derived from 2-3-day streptoz...   \n",
       "\n",
       "                                               TFIDF  \\\n",
       "0  {'rat': 0.09393489570187145, 'common': 0.02869...   \n",
       "1  {'rat': 0.023617916633613394, 'use': 0.0147841...   \n",
       "2  {'rat': 0.10226314418677966, 'use': 0.01066898...   \n",
       "3  {'model': 0.038714646134547365, 'develop': 0.0...   \n",
       "4  {'rat': 0.030615817858387732, 'anim': 0.080179...   \n",
       "\n",
       "                                        Abstract_W2V  \\\n",
       "0  [-0.03999741, 0.062728785, -0.002549661, 0.049...   \n",
       "1  [0.014284923, 0.03845855, 0.020136734, 0.05924...   \n",
       "2  [-0.020149924, 0.047227394, 0.012617389, 0.035...   \n",
       "3  [-0.045007102, 0.025433676, -0.005037438, 0.06...   \n",
       "4  [-0.028360292, 0.05821858, 0.015442131, 0.0421...   \n",
       "\n",
       "                                      bert_embedding  \n",
       "0  [ 5.83067238e-02 -7.34468549e-03 -7.10018054e-...  \n",
       "1  [ 8.21016803e-02 -9.57140699e-03 -8.19785297e-...  \n",
       "2  [ 6.06562942e-02 -2.23077759e-02 -8.84668827e-...  \n",
       "3  [ 5.10609150e-02 -4.73604724e-03 -7.53103644e-...  \n",
       "4  [ 6.99397400e-02 -1.28354207e-02 -8.73763263e-...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display some entries\n",
    "df_with_EMBS[['PMID', 'Abstract', 'TFIDF', 'Abstract_W2V', 'bert_embedding']].head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
